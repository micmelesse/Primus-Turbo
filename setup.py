import glob
import os
import platform
import re
import subprocess

from setuptools import find_packages, setup
from torch.utils.cpp_extension import BuildExtension, CUDAExtension

PROJECT_ROOT = os.path.abspath(os.path.dirname(__file__))

DEFAULT_HIPCC = "/opt/rocm/bin/hipcc"


def setup_cxx_env():
    user_cxx = os.environ.get("CXX")
    if user_cxx:
        print(f"[Primus-Turbo Setup] Using user-provided CXX: {user_cxx}")
    else:
        os.environ["CXX"] = DEFAULT_HIPCC
        print(f"[Primus-Turbo Setup] No CXX provided. Defaulting to: {DEFAULT_HIPCC}")

    os.environ.setdefault("CMAKE_CXX_COMPILER", os.environ["CXX"])
    os.environ.setdefault("CMAKE_HIP_COMPILER", os.environ["CXX"])
    print(f"[Primus-Turbo Setup] CMAKE_CXX_COMPILER set to: {os.environ['CMAKE_CXX_COMPILER']}")
    print(f"[Primus-Turbo Setup] CMAKE_HIP_COMPILER set to: {os.environ['CMAKE_HIP_COMPILER']}")


def read_version():
    with open(os.path.join("primus_turbo", "__init__.py")) as f:
        for line in f:
            match = re.match(r"^__version__\s*=\s*[\"'](.+?)[\"']", line)
            if match:
                return match.group(1)
    raise RuntimeError("Cannot find version.")


def build_torch_extension():
    arch = platform.machine().lower()

    libraries = ["hipblas"]

    extra_link_args = [
        "-Wl,-rpath,$ORIGIN/../../torch/lib",
        "-Wl,-rpath,/opt/rocm/lib",
        f"-L/usr/lib/{arch}-linux-gnu",
    ]

    cxx_flags = [
        "-O3",
        "-fvisibility=hidden",
    ]

    # TODO: consider rocm version
    nvcc_flags = [
        "-O3",
        "-U__HIP_NO_HALF_OPERATORS__",
        "-U__HIP_NO_HALF_CONVERSIONS__",
        "-U__HIP_NO_BFLOAT16_OPERATORS__",
        "-U__HIP_NO_BFLOAT16_CONVERSIONS__",
        "-U__HIP_NO_BFLOAT162_OPERATORS__",
        "-U__HIP_NO_BFLOAT162_CONVERSIONS__",
        "-fno-offload-uniform-block",
        "-mllvm",
        "--lsr-drop-solution=1",
        "-mllvm",
        "-enable-post-misched=0",
        "-mllvm",
        "-amdgpu-coerce-illegal-types=1",
        "-mllvm",
        "-amdgpu-early-inline-all=true",
        "-mllvm",
        "-amdgpu-function-calls=false",
    ]

    max_jobs = int(os.getenv("MAX_JOBS", "4"))
    nvcc_flags.append(f"-parallel-jobs={max_jobs}")

    # Include
    ck_include_dir = os.path.join(PROJECT_ROOT, "3rdparty", "composable_kernel", "include")

    # CPP
    cu_sources = []
    cpp_sources = []
    cu_sources += glob.glob("csrc/kernels/**/*.cu", recursive=True)
    cu_sources += glob.glob("csrc/pytorch/**/*.cu", recursive=True)
    cpp_sources += glob.glob("csrc/pytorch/**/*.cpp", recursive=True)
    sources = ["csrc/pytorch/bindings_pytorch.cpp"] + cu_sources + cpp_sources

    return CUDAExtension(
        name="primus_turbo.pytorch._C",
        sources=sources,
        include_dirs=[
            "csrc/include",
            os.path.abspath("csrc/include"),
            ck_include_dir,
        ],
        libraries=libraries,
        extra_link_args=extra_link_args,
        extra_compile_args={
            "cxx": cxx_flags,
            "nvcc": nvcc_flags,
        },
    )


def compile_aiter():
    aiter_dir = os.path.join("3rdparty", "aiter")
    subprocess.run(["python3", "setup.py", "develop"], cwd=aiter_dir, check=True)


if __name__ == "__main__":
    # set cxx
    setup_cxx_env()
    # Compile aiter before setting up the main package
    compile_aiter()

    setup(
        name="primus_turbo",
        version=read_version(),
        packages=find_packages(),
        ext_modules=[build_torch_extension()],
        cmdclass={"build_ext": BuildExtension.with_options(use_ninja=True)},
    )
